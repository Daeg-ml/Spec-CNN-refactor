{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "RjoK0CooyLaq",
    "outputId": "76121181-306b-4789-ec44-363c569cbddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "'''Cleared and good to go'''\n",
    "\n",
    "\n",
    "#import pandas for data processing\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6znpiKhys4I"
   },
   "outputs": [],
   "source": [
    "def fname_ls_builder(fin_path,initial=True):\n",
    "  #Find all files in data directory\n",
    "  from os import listdir\n",
    "  from os.path import isfile, join\n",
    "  if initial:\n",
    "    return [f for f in listdir(fin_path) if isfile(join(fin_path,f)) and (not ('_ds' in f or '_r' in f))]\n",
    "  else:\n",
    "    return [f for f in listdir(fin_path) if (isfile(join(fin_path,f)) and ('_ds' in f or '_r' in f))]\n",
    "\n",
    "def df_builder(fin_path,fname_ls):\n",
    "  #this function imports data from CSV files to one large dataframe\n",
    "\n",
    "  #create list to hold dataframes\n",
    "  df_ls=[]\n",
    "\n",
    "  #read in each file\n",
    "  for i in fname_ls:\n",
    "    temp_df=pd.read_csv(fin_path+i,index_col=0)\n",
    "    #print(i,'loaded\\n\\n')\n",
    "    df_ls.append(temp_df)\n",
    "\n",
    "  #create one large df\n",
    "  df=pd.concat(df_ls)\n",
    "  #print(df.shape)\n",
    "  return df\n",
    "\n",
    "def split_data(X):\n",
    "  #separate y from X\n",
    "  y=X['label']\n",
    "  X.drop(['label'],axis=1,inplace=True)\n",
    "  #split into train and dev sets\n",
    "  #print(X,'\\n\\n',y)\n",
    "  return X,y\n",
    "\n",
    "\n",
    "#set filepaths for import/export\n",
    "pkin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Peaks Only/Labeled/'\n",
    "\n",
    "pk_fname_ls=fname_ls_builder(pkin_path)\n",
    "\n",
    "pk_df=df_builder(pkin_path,pk_fname_ls)\n",
    "\n",
    "#drop relative intensities\n",
    "pk_df.drop(columns=[i for i in pk_df.columns.values if 'val' in i],inplace=True)\n",
    "\n",
    "pk_df,y=split_data(pk_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QrntHBDDJuJ"
   },
   "outputs": [],
   "source": [
    "#split into train and dev sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(pk_df, y, test_size = 0.20, random_state = 0)\n",
    "#print(X_train,'\\n\\n',X_dev,'\\n\\n',y_train,'\\n\\n',y_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GmzJl-v63Jg"
   },
   "outputs": [],
   "source": [
    "#scale data((X-mean)/std_dev)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_dev_sc = sc.fit_transform(X_dev)\n",
    "#print(X_train_sc,'\\n\\n',X_dev_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "uamWMnnsWEgl",
    "outputId": "4f62b516-dbc2-4bff-f889-cb343c296afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.55077372 -0.53261802 -0.18376973]\n",
      " [-0.95171254 -0.10686832 -0.89272098]\n",
      " [-0.96887411 -0.72460948 -0.64312601]\n",
      " ...\n",
      " [ 1.78146066  1.36337326 -0.74502505]\n",
      " [ 2.49075431 -1.61397089  0.94416909]\n",
      " [-0.11372039  0.48127858 -0.96585522]] \n",
      "\n",
      " [[-1.42129126 -0.68002136  0.25951888]\n",
      " [-0.72243006  1.67579112  1.17003539]\n",
      " [-1.02074385 -0.22171037 -0.90992554]\n",
      " ...\n",
      " [ 1.09414636  2.13876056  0.44570693]\n",
      " [-1.2193332  -0.62481069  0.80210811]\n",
      " [-1.01213001 -0.66026732 -0.5953985 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#run PCA\n",
    "X_train_p=PCA(n_components=3).fit_transform(X_train_sc)\n",
    "X_dev_p=PCA(n_components=3).fit_transform(X_dev_sc)\n",
    "#print(X_train_p,'\\n\\n',X_dev_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Puy0uSDafO0s"
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "model=LogisticRegression(max_iter=500).fit(X_train_sc,y_train)\n",
    "modelp=LogisticRegression(max_iter=500).fit(X_train_p,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "UIsiKSe5wGc9",
    "outputId": "d136efdf-a28e-4cab-8df3-a1dfcc7f2cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8274986395791765\n",
      "0.7209323417377108\n"
     ]
    }
   ],
   "source": [
    "#check model\n",
    "print(model.score(X_dev_sc,y_dev))\n",
    "print(modelp.score(X_dev_p,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "vVFT7gaqw2X8",
    "outputId": "e44bb61a-41ed-48c0-9c58-9f91186e50ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1776   86    0    9    0    2    0    5  138]\n",
      " [ 130 1010    1    0    0    0    0    0   22]\n",
      " [   3    1  546   36    0    9  382   16    1]\n",
      " [   0    0   41 1074    4    5   29    1    4]\n",
      " [   0    2    0    0 1245    0    0    2    0]\n",
      " [  45   30    7    6    0  923    0    0   11]\n",
      " [   0    0  126    7    0    0  992    1    1]\n",
      " [   0    0    0    0    1    0    0 1153    0]\n",
      " [  86  544    6   19    2   80    0    1  405]] \n",
      "\n",
      "\n",
      " [[1775  101    0   72    2   53    0    2   11]\n",
      " [ 151 1008    0    3    0    1    0    0    0]\n",
      " [  37    4  509    2    3   16  412    7    4]\n",
      " [ 325  370    7  334    8    8   47    0   59]\n",
      " [   0    2    0    0 1244    0    0    3    0]\n",
      " [  46   31    0    9    0  926    3    0    7]\n",
      " [  27   16  137    0    1    1  944    0    1]\n",
      " [   0    0    0    0    3    0    0 1151    0]\n",
      " [ 153  555    0  268    2  106    1    0   58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_dev,model.predict(X_dev_sc))\n",
    "pcm=confusion_matrix(y_dev,modelp.predict(X_dev_p))\n",
    "print(cm,'\\n\\n\\n',pcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9TlLDQO7TNp"
   },
   "outputs": [],
   "source": [
    "testin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Peaks Only/Unlabeled/'\n",
    "test_ls=fname_ls_builder(testin_path)\n",
    "test_df=df_builder(testin_path,test_ls)\n",
    "test_df.drop(columns=[i for i in test_df.columns.values if 'val' in i],inplace=True)\n",
    "X_test=sc.fit_transform(test_df)\n",
    "X_test_p=PCA(n_components=3).fit_transform(X_test)\n",
    "\n",
    "saved_data=r'/content/drive/My Drive/ML Spectroscopy/Programs/Data Processing/Saved Lists/'\n",
    "\n",
    "pd.DataFrame(data=model.predict_proba(X_test),index=test_df.index.values,columns=sorted(y.unique())).to_csv(saved_data+r'log_reg_non-synth.csv')\n",
    "pd.DataFrame(data=modelp.predict_proba(X_test_p),index=test_df.index.values,columns=sorted(y.unique())).to_csv(saved_data+r'log_reg_non-synth_pca.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyhFtnyDJ7m8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "logistic_regression_non_synth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
