{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Traditional Models</h1>\n",
    "\n",
    "<p>This notebook is used to train and explore a series of machine learning models including logistic regression, linear support vector classification (SVC), and an ensemble of binary random forest classifiers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26730,
     "status": "ok",
     "timestamp": 1593641782515,
     "user": {
      "displayName": "Nathan Temiquel",
      "photoUrl": "",
      "userId": "01657354188638757810"
     },
     "user_tz": 420
    },
    "id": "RjoK0CooyLaq",
    "outputId": "8bb8fc78-e7fe-41ef-8e20-dafce951c243"
   },
   "outputs": [],
   "source": [
    "import tradmodels as tmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgHv6RqnMtT2"
   },
   "source": [
    "<h1>Training the Logistic Regression Model</h1>\n",
    "\n",
    "<p>If you need to retrain the models, be sure to restart the runtime</p>\n",
    "\n",
    "<h3>Train below</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRFjOvNOzp9E"
   },
   "outputs": [],
   "source": [
    "'''define the filepaths for your data here!'''\n",
    "\n",
    "output_label='testing_1_1-11'\n",
    "training_set_path='Data/CWT Data/Single/'\n",
    "test_set_path='Data/CWT Data/Mixed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master data set shape is (71674, 951) \n",
      "\n",
      " Master data set is\n",
      "                                150       151       152       153       154  \\\n",
      "albite_train_015s_5250-0 -0.060426  0.364363  0.655384  0.748199  0.667854   \n",
      "albite_train_015s_5250-1 -0.050979  0.370427  0.661060  0.755651  0.676321   \n",
      "albite_train_015s_5250-2 -0.065293  0.378984  0.688549  0.793750  0.715698   \n",
      "albite_train_015s_5250-3 -0.054342  0.375322  0.671679  0.768352  0.688044   \n",
      "albite_train_015s_5250-4 -0.054718  0.385046  0.688442  0.786872  0.702929   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.003787  0.043815  0.070439  0.077455  0.067289   \n",
      "qtz_train_015s_625-621    0.004155  0.043077  0.068879  0.075580  0.065538   \n",
      "qtz_train_015s_625-622    0.003540  0.042567  0.068623  0.075576  0.065634   \n",
      "qtz_train_015s_625-623    0.003601  0.043714  0.070567  0.077919  0.068031   \n",
      "qtz_train_015s_625-624    0.004089  0.042137  0.067314  0.073799  0.063936   \n",
      "\n",
      "                               155       156       157       158       159  \\\n",
      "albite_train_015s_5250-0  0.496181  0.318162  0.185195  0.109323  0.077749   \n",
      "albite_train_015s_5250-1  0.501629  0.314986  0.169079  0.079796  0.039225   \n",
      "albite_train_015s_5250-2  0.534693  0.337332  0.179948  0.081911  0.037798   \n",
      "albite_train_015s_5250-3  0.510962  0.322309  0.175963  0.087966  0.049388   \n",
      "albite_train_015s_5250-4  0.518523  0.321335  0.167549  0.074912  0.035545   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.048019  0.028216  0.013206  0.004299  0.000159   \n",
      "qtz_train_015s_625-621    0.046543  0.026883  0.011815  0.002833 -0.001107   \n",
      "qtz_train_015s_625-622    0.046558  0.026746  0.011615  0.002744 -0.000960   \n",
      "qtz_train_015s_625-623    0.048767  0.028588  0.012938  0.003450 -0.000850   \n",
      "qtz_train_015s_625-624    0.045365  0.026184  0.011491  0.002694 -0.001256   \n",
      "\n",
      "                          ...      1091      1092      1093      1094  \\\n",
      "albite_train_015s_5250-0  ...  0.033498  0.094618  0.217422  0.412980   \n",
      "albite_train_015s_5250-1  ...  0.076453  0.142140  0.255032  0.426998   \n",
      "albite_train_015s_5250-2  ...  0.054740  0.131200  0.259925  0.450937   \n",
      "albite_train_015s_5250-3  ...  0.035153  0.118537  0.257787  0.457909   \n",
      "albite_train_015s_5250-4  ...  0.049010  0.125969  0.259054  0.455346   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    ...  0.002606  0.007139  0.015264  0.027574   \n",
      "qtz_train_015s_625-621    ...  0.002133  0.006294  0.013861  0.025481   \n",
      "qtz_train_015s_625-622    ...  0.001191  0.005387  0.013221  0.025251   \n",
      "qtz_train_015s_625-623    ...  0.001359  0.006321  0.014808  0.027324   \n",
      "qtz_train_015s_625-624    ...  0.007947  0.004349  0.007085  0.017442   \n",
      "\n",
      "                              1095      1096      1097      1098      1099  \\\n",
      "albite_train_015s_5250-0  0.660274  0.891085  1.000000  0.889898  0.534820   \n",
      "albite_train_015s_5250-1  0.643002  0.844503  0.936010  0.826456  0.489260   \n",
      "albite_train_015s_5250-2  0.686345  0.903073  1.000000  0.881721  0.521713   \n",
      "albite_train_015s_5250-3  0.696824  0.910374  1.000000  0.875015  0.513028   \n",
      "albite_train_015s_5250-4  0.693414  0.908336  1.000000  0.876104  0.513243   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.042753  0.056629  0.062749  0.055183  0.032422   \n",
      "qtz_train_015s_625-621    0.039995  0.053479  0.059751  0.053037  0.031741   \n",
      "qtz_train_015s_625-622    0.040261  0.054273  0.060999  0.054494  0.033011   \n",
      "qtz_train_015s_625-623    0.042554  0.056411  0.062566  0.055176  0.032730   \n",
      "qtz_train_015s_625-624    0.033172  0.048732  0.056808  0.051271  0.030684   \n",
      "\n",
      "                          label  \n",
      "albite_train_015s_5250-0      1  \n",
      "albite_train_015s_5250-1      1  \n",
      "albite_train_015s_5250-2      1  \n",
      "albite_train_015s_5250-3      1  \n",
      "albite_train_015s_5250-4      1  \n",
      "...                         ...  \n",
      "qtz_train_015s_625-620        0  \n",
      "qtz_train_015s_625-621        0  \n",
      "qtz_train_015s_625-622        0  \n",
      "qtz_train_015s_625-623        0  \n",
      "qtz_train_015s_625-624        0  \n",
      "\n",
      "[71674 rows x 951 columns]\n",
      "0.9669683810321072\n",
      "Model label  Log Reg \n",
      " [[7651    3   11  365    1    0    3    1    4    1    0    4]\n",
      " [   0 4621    0    0    1    0    2    0   14   52    1    0]\n",
      " [  26   12 3498  404    8    3    7    2   12   57    0    0]\n",
      " [  17   23  117 5107   14    1   14    2   41   41    4    4]\n",
      " [   3    3    4    7 5075    0    1    2    2   11    1    0]\n",
      " [   0    0    1    4    0 4038    0    0    1    0    0    0]\n",
      " [   8    3    2   16    2    1 4394    1   13    3    1    0]\n",
      " [   1    1    2   13    1    0    3 4462    1    0    1    0]\n",
      " [   8   18   30   73    2    3   13    4 4213   71    0    1]\n",
      " [   0  110   62   30    0    0    3    2   62 4298    0    0]\n",
      " [   0    0    0   11    0    0    1    0    0    0 4081    0]\n",
      " [   0    0    0    4    0    0    0    0    0    1    0 4007]] \n",
      "\n",
      "\n",
      "\n",
      "Model prectictions [[5.78499772e-11 2.52554196e-12 4.66105742e-12 ... 5.19799983e-13\n",
      "  3.53310462e-12 5.51412682e-15]\n",
      " [9.99999433e-01 4.15477785e-15 5.65936637e-07 ... 1.74002862e-16\n",
      "  1.93820591e-13 2.50200601e-16]\n",
      " [1.85518736e-19 9.97502581e-01 1.12711423e-22 ... 2.49075929e-03\n",
      "  3.39021320e-18 8.51957735e-19]\n",
      " ...\n",
      " [2.27221813e-02 1.09924404e-05 5.28791638e-02 ... 4.96867189e-03\n",
      "  7.71183018e-04 1.20361810e-05]\n",
      " [4.50372441e-02 5.93259912e-03 1.38638771e-01 ... 5.30503783e-01\n",
      "  1.57093316e-03 1.20572808e-03]\n",
      " [7.22226417e-08 9.70611030e-01 2.41223155e-09 ... 2.75985154e-02\n",
      "  1.18423170e-07 9.55998564e-07]]\n",
      "0.9651900941750959\n",
      "Model label  Log Reg \n",
      " [[1895    0    3   88    0    0    0    1    0    1    0    0]\n",
      " [   0 1165    0    0    1    0    1    0    6   10    1    0]\n",
      " [   6    0  881  107    1    0    3    2    4   20    1    0]\n",
      " [   7    6   28 1358    6    2    3    0   11   15    1    3]\n",
      " [   2    0    0    2 1286    0    1    0    0    0    0    0]\n",
      " [   0    0    1    3    0  989    0    0    3    0    0    0]\n",
      " [   1    1    1    5    1    0 1142    0    4    1    0    0]\n",
      " [   0    0    0    1    0    0    0 1113    1    0    0    0]\n",
      " [   0    3   10   19    1    0    3    3 1109   16    0    0]\n",
      " [   1   25   15   12    1    1    1    0   17  960    0    0]\n",
      " [   0    0    0    3    0    0    0    0    1    0  935    0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0 1003]] \n",
      "\n",
      "\n",
      "\n",
      "Model prectictions [[4.89492273e-08 6.78404194e-01 4.27161023e-08 ... 2.98966844e-01\n",
      "  3.17858668e-08 1.48415795e-07]\n",
      " [2.19790158e-19 9.98225702e-01 7.24895648e-23 ... 1.75489278e-03\n",
      "  3.56407054e-18 9.42688942e-19]\n",
      " [1.41872287e-19 9.98683256e-01 2.85987774e-23 ... 1.29972341e-03\n",
      "  9.36672304e-19 6.30078542e-19]\n",
      " ...\n",
      " [5.15314846e-15 3.88869174e-22 1.02901604e-18 ... 8.18128741e-20\n",
      "  5.41517556e-18 4.15142547e-18]\n",
      " [3.15194683e-04 1.93966748e-10 1.07393990e-13 ... 6.76763824e-08\n",
      "  1.89067151e-07 1.35791970e-09]\n",
      " [1.71411132e-05 7.80536461e-08 5.35730031e-08 ... 8.27313417e-06\n",
      "  5.49339297e-09 8.64788436e-09]]\n",
      "Master data set shape is (23271, 951) \n",
      "\n",
      " Master data set is\n",
      "                                  150       151       152       153       154  \\\n",
      "foalb_train_15s_5250-0      0.001477  0.447495  0.752738  0.849649  0.762673   \n",
      "foalb_train_15s_5250-1      0.003746  0.473147  0.794257  0.896555  0.806179   \n",
      "foalb_train_15s_5250-2      0.003452  0.472323  0.794269  0.897811  0.807572   \n",
      "foalb_train_15s_5250-3      0.000553  0.490699  0.830030  0.942299  0.850849   \n",
      "foalb_train_15s_5250-4      0.003594  0.473044  0.794657  0.897992  0.808759   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995 -0.043718  0.495214  0.871431  1.000000  0.906045   \n",
      "qtzalb_train_60s_3000-2996 -0.044028  0.481457  0.850450  0.978827  0.889248   \n",
      "qtzalb_train_60s_3000-2997 -0.030482  0.494818  0.861374  0.984281  0.886081   \n",
      "qtzalb_train_60s_3000-2998 -0.046903  0.490378  0.867953  1.000000  0.909799   \n",
      "qtzalb_train_60s_3000-2999 -0.042390  0.484819  0.851979  0.975129  0.879023   \n",
      "\n",
      "                                 155       156       157       158       159  \\\n",
      "foalb_train_15s_5250-0      0.575121  0.374501  0.214882  0.110848  0.052384   \n",
      "foalb_train_15s_5250-1      0.610553  0.400672  0.231894  0.118449  0.050007   \n",
      "foalb_train_15s_5250-2      0.610030  0.396653  0.224569  0.110042  0.043800   \n",
      "foalb_train_15s_5250-3      0.644262  0.417962  0.233161  0.109190  0.038269   \n",
      "foalb_train_15s_5250-4      0.613535  0.402683  0.231916  0.117012  0.049544   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  0.687470  0.450134  0.261362  0.140541  0.075679   \n",
      "qtzalb_train_60s_3000-2996  0.676007  0.442381  0.254903  0.133389  0.066652   \n",
      "qtzalb_train_60s_3000-2997  0.662341  0.419229  0.227013  0.108424  0.052630   \n",
      "qtzalb_train_60s_3000-2998  0.693727  0.457279  0.268487  0.147722  0.083483   \n",
      "qtzalb_train_60s_3000-2999  0.661224  0.428035  0.247301  0.137564  0.084017   \n",
      "\n",
      "                            ...      1091      1092      1093      1094  \\\n",
      "foalb_train_15s_5250-0      ...  0.043605  0.108542  0.231170  0.423100   \n",
      "foalb_train_15s_5250-1      ...  0.060088  0.132701  0.256954  0.444917   \n",
      "foalb_train_15s_5250-2      ...  0.050517  0.116672  0.240004  0.431777   \n",
      "foalb_train_15s_5250-3      ...  0.048278  0.117221  0.243527  0.437172   \n",
      "foalb_train_15s_5250-4      ...  0.026982  0.096095  0.226407  0.426401   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  ...  0.052431  0.120275  0.244638  0.435690   \n",
      "qtzalb_train_60s_3000-2996  ...  0.053233  0.121710  0.246460  0.438206   \n",
      "qtzalb_train_60s_3000-2997  ...  0.028918  0.101945  0.234712  0.434680   \n",
      "qtzalb_train_60s_3000-2998  ...  0.057637  0.117994  0.235801  0.423637   \n",
      "qtzalb_train_60s_3000-2999  ...  0.050512  0.123393  0.252465  0.446472   \n",
      "\n",
      "                                1095      1096      1097      1098      1099  \\\n",
      "foalb_train_15s_5250-0      0.665607  0.892756  1.000000  0.889557  0.534266   \n",
      "foalb_train_15s_5250-1      0.679952  0.899042  1.000000  0.885818  0.528646   \n",
      "foalb_train_15s_5250-2      0.672732  0.896805  1.000000  0.885514  0.527092   \n",
      "foalb_train_15s_5250-3      0.677976  0.899930  1.000000  0.882585  0.522179   \n",
      "foalb_train_15s_5250-4      0.673323  0.898984  1.000000  0.882515  0.523523   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  0.673449  0.892330  0.990129  0.872321  0.514130   \n",
      "qtzalb_train_60s_3000-2996  0.677611  0.899222  1.000000  0.883834  0.524544   \n",
      "qtzalb_train_60s_3000-2997  0.679372  0.901830  1.000000  0.880722  0.520925   \n",
      "qtzalb_train_60s_3000-2998  0.662419  0.885848  0.989848  0.877629  0.522615   \n",
      "qtzalb_train_60s_3000-2999  0.685111  0.903437  1.000000  0.880402  0.519435   \n",
      "\n",
      "                            label  \n",
      "foalb_train_15s_5250-0         14  \n",
      "foalb_train_15s_5250-1         14  \n",
      "foalb_train_15s_5250-2         14  \n",
      "foalb_train_15s_5250-3         14  \n",
      "foalb_train_15s_5250-4         14  \n",
      "...                           ...  \n",
      "qtzalb_train_60s_3000-2995     12  \n",
      "qtzalb_train_60s_3000-2996     12  \n",
      "qtzalb_train_60s_3000-2997     12  \n",
      "qtzalb_train_60s_3000-2998     12  \n",
      "qtzalb_train_60s_3000-2999     12  \n",
      "\n",
      "[23271 rows x 951 columns]\n"
     ]
    }
   ],
   "source": [
    "'''train the model'''\n",
    "test_outputs_df,model,pca=tmodel.classic_model(training_set_path,test_set_path,output_label,False,1,r'Logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgHv6RqnMtT2"
   },
   "source": [
    "<h1>Training the Support Vector Classifier (SVC) Model</h1>\n",
    "\n",
    "<p>If you need to retrain the models, be sure to restart the runtime</p>\n",
    "\n",
    "<h3>Train below</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRFjOvNOzp9E"
   },
   "outputs": [],
   "source": [
    "'''define the filepaths for your data here!'''\n",
    "\n",
    "output_label='testing_1_1-11(1)'\n",
    "training_set_path='Data/CWT Data/Single/'\n",
    "test_set_path='Data/CWT Data/Mixed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master data set shape is (71674, 951) \n",
      "\n",
      " Master data set is\n",
      "                                150       151       152       153       154  \\\n",
      "albite_train_015s_5250-0 -0.060426  0.364363  0.655384  0.748199  0.667854   \n",
      "albite_train_015s_5250-1 -0.050979  0.370427  0.661060  0.755651  0.676321   \n",
      "albite_train_015s_5250-2 -0.065293  0.378984  0.688549  0.793750  0.715698   \n",
      "albite_train_015s_5250-3 -0.054342  0.375322  0.671679  0.768352  0.688044   \n",
      "albite_train_015s_5250-4 -0.054718  0.385046  0.688442  0.786872  0.702929   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.003787  0.043815  0.070439  0.077455  0.067289   \n",
      "qtz_train_015s_625-621    0.004155  0.043077  0.068879  0.075580  0.065538   \n",
      "qtz_train_015s_625-622    0.003540  0.042567  0.068623  0.075576  0.065634   \n",
      "qtz_train_015s_625-623    0.003601  0.043714  0.070567  0.077919  0.068031   \n",
      "qtz_train_015s_625-624    0.004089  0.042137  0.067314  0.073799  0.063936   \n",
      "\n",
      "                               155       156       157       158       159  \\\n",
      "albite_train_015s_5250-0  0.496181  0.318162  0.185195  0.109323  0.077749   \n",
      "albite_train_015s_5250-1  0.501629  0.314986  0.169079  0.079796  0.039225   \n",
      "albite_train_015s_5250-2  0.534693  0.337332  0.179948  0.081911  0.037798   \n",
      "albite_train_015s_5250-3  0.510962  0.322309  0.175963  0.087966  0.049388   \n",
      "albite_train_015s_5250-4  0.518523  0.321335  0.167549  0.074912  0.035545   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.048019  0.028216  0.013206  0.004299  0.000159   \n",
      "qtz_train_015s_625-621    0.046543  0.026883  0.011815  0.002833 -0.001107   \n",
      "qtz_train_015s_625-622    0.046558  0.026746  0.011615  0.002744 -0.000960   \n",
      "qtz_train_015s_625-623    0.048767  0.028588  0.012938  0.003450 -0.000850   \n",
      "qtz_train_015s_625-624    0.045365  0.026184  0.011491  0.002694 -0.001256   \n",
      "\n",
      "                          ...      1091      1092      1093      1094  \\\n",
      "albite_train_015s_5250-0  ...  0.033498  0.094618  0.217422  0.412980   \n",
      "albite_train_015s_5250-1  ...  0.076453  0.142140  0.255032  0.426998   \n",
      "albite_train_015s_5250-2  ...  0.054740  0.131200  0.259925  0.450937   \n",
      "albite_train_015s_5250-3  ...  0.035153  0.118537  0.257787  0.457909   \n",
      "albite_train_015s_5250-4  ...  0.049010  0.125969  0.259054  0.455346   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    ...  0.002606  0.007139  0.015264  0.027574   \n",
      "qtz_train_015s_625-621    ...  0.002133  0.006294  0.013861  0.025481   \n",
      "qtz_train_015s_625-622    ...  0.001191  0.005387  0.013221  0.025251   \n",
      "qtz_train_015s_625-623    ...  0.001359  0.006321  0.014808  0.027324   \n",
      "qtz_train_015s_625-624    ...  0.007947  0.004349  0.007085  0.017442   \n",
      "\n",
      "                              1095      1096      1097      1098      1099  \\\n",
      "albite_train_015s_5250-0  0.660274  0.891085  1.000000  0.889898  0.534820   \n",
      "albite_train_015s_5250-1  0.643002  0.844503  0.936010  0.826456  0.489260   \n",
      "albite_train_015s_5250-2  0.686345  0.903073  1.000000  0.881721  0.521713   \n",
      "albite_train_015s_5250-3  0.696824  0.910374  1.000000  0.875015  0.513028   \n",
      "albite_train_015s_5250-4  0.693414  0.908336  1.000000  0.876104  0.513243   \n",
      "...                            ...       ...       ...       ...       ...   \n",
      "qtz_train_015s_625-620    0.042753  0.056629  0.062749  0.055183  0.032422   \n",
      "qtz_train_015s_625-621    0.039995  0.053479  0.059751  0.053037  0.031741   \n",
      "qtz_train_015s_625-622    0.040261  0.054273  0.060999  0.054494  0.033011   \n",
      "qtz_train_015s_625-623    0.042554  0.056411  0.062566  0.055176  0.032730   \n",
      "qtz_train_015s_625-624    0.033172  0.048732  0.056808  0.051271  0.030684   \n",
      "\n",
      "                          label  \n",
      "albite_train_015s_5250-0      1  \n",
      "albite_train_015s_5250-1      1  \n",
      "albite_train_015s_5250-2      1  \n",
      "albite_train_015s_5250-3      1  \n",
      "albite_train_015s_5250-4      1  \n",
      "...                         ...  \n",
      "qtz_train_015s_625-620        0  \n",
      "qtz_train_015s_625-621        0  \n",
      "qtz_train_015s_625-622        0  \n",
      "qtz_train_015s_625-623        0  \n",
      "qtz_train_015s_625-624        0  \n",
      "\n",
      "[71674 rows x 951 columns]\n",
      "0.9355761349168977\n",
      "Model label  SVC \n",
      " [[7462    0    5    3    2    0    1    1    2    1    0    2  565]\n",
      " [   1 4346    1    0    3    0    4    0    4    5    0    1  326]\n",
      " [  23    1 2587   21    6    2    6    0   18    3    0    0 1362]\n",
      " [  14    7   99  601   14    2   11    6   43    9    6    3 4570]\n",
      " [   0    3    4    2 5042    0    0    1    2    0    0    1   54]\n",
      " [   0    0    1    0    0 4030    0    0    1    0    0    0   12]\n",
      " [   2    1    1    1    3    1 4346    1    5    0    0    0   83]\n",
      " [   1    0    1    0    1    0    3 4453    0    0    0    0   26]\n",
      " [   6    3   19    6    3    2    7    4 2622    3    0    2 1759]\n",
      " [   0  114    2    0    1    0    3    1   20 2320    0    1 2105]\n",
      " [   0    0    0    1    0    0    1    0    0    0 4073    0   18]\n",
      " [   0    0    2    0    0    0    0    0    0    0    0 4008    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0]] \n",
      "\n",
      "\n",
      "\n",
      "Model prectictions [[-1.59080139 -1.10860847 -3.07036064 ... -1.11801695 -2.99572799\n",
      "  -3.34874147]\n",
      " [ 2.72451244 -2.09667975 -1.2263762  ... -3.35305631 -1.7040402\n",
      "  -4.07830727]\n",
      " [-1.66251199  1.94182773 -4.29641596 ... -0.76868606 -2.51517086\n",
      "  -6.31408117]\n",
      " ...\n",
      " [-0.92733469 -2.18495786 -0.83336674 ... -0.75393895 -1.28263664\n",
      "  -2.60954192]\n",
      " [-0.99996332 -1.62607424 -0.85855915 ... -0.81244259 -1.54494797\n",
      "  -2.19644452]\n",
      " [-1.20713186  0.11436108 -2.86927424 ... -1.09004135 -1.99074484\n",
      "  -2.78035145]]\n",
      "0.9356818974537845\n",
      "Model label  SVC \n",
      " [[1835    0    0    0    0    0    0    1    1    1    0    0  150]\n",
      " [   0 1103    0    0    1    0    1    0    1    3    0    0   75]\n",
      " [   6    0  648    9    1    0    2    2    7    1    1    0  348]\n",
      " [   7    1   28  178    5    0    4    2   15    6    1    0 1193]\n",
      " [   0    0    1    1 1283    0    0    0    1    0    0    0    5]\n",
      " [   0    1    1    0    0  988    0    0    1    0    0    0    5]\n",
      " [   0    0    1    0    1    0 1137    0    3    0    0    0   14]\n",
      " [   0    0    0    0    0    0    0 1110    0    0    0    0    5]\n",
      " [   0    1    5    0    1    0    3    1  719    2    0    0  432]\n",
      " [   1   30    2    1    0    0    1    0    9  492    0    0  497]\n",
      " [   0    0    0    0    0    1    0    1    1    0  932    0    4]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0 1003    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0]] \n",
      "\n",
      "\n",
      "\n",
      "Model prectictions [[-1.27001331  0.03663119 -1.6760474  ... -0.97492783 -1.93952047\n",
      "  -3.12608269]\n",
      " [-1.66151806  2.01080833 -4.32584951 ... -0.8323103  -2.53319443\n",
      "  -6.25244303]\n",
      " [-1.59971422  2.09047289 -4.41208196 ... -0.92861494 -2.6526441\n",
      "  -6.29630699]\n",
      " ...\n",
      " [-0.63538859 -3.85155834 -6.61111424 ... -2.46502656 -2.10384401\n",
      "  -5.55218989]\n",
      " [-0.97347063 -2.50851576 -5.19357079 ... -0.90883118 -1.23408734\n",
      "  -2.44692898]\n",
      " [-1.18804004 -1.47217282 -1.81869123 ... -0.92586171 -2.25047408\n",
      "  -2.61043748]]\n",
      "Master data set shape is (23271, 951) \n",
      "\n",
      " Master data set is\n",
      "                                  150       151       152       153       154  \\\n",
      "foalb_train_15s_5250-0      0.001477  0.447495  0.752738  0.849649  0.762673   \n",
      "foalb_train_15s_5250-1      0.003746  0.473147  0.794257  0.896555  0.806179   \n",
      "foalb_train_15s_5250-2      0.003452  0.472323  0.794269  0.897811  0.807572   \n",
      "foalb_train_15s_5250-3      0.000553  0.490699  0.830030  0.942299  0.850849   \n",
      "foalb_train_15s_5250-4      0.003594  0.473044  0.794657  0.897992  0.808759   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995 -0.043718  0.495214  0.871431  1.000000  0.906045   \n",
      "qtzalb_train_60s_3000-2996 -0.044028  0.481457  0.850450  0.978827  0.889248   \n",
      "qtzalb_train_60s_3000-2997 -0.030482  0.494818  0.861374  0.984281  0.886081   \n",
      "qtzalb_train_60s_3000-2998 -0.046903  0.490378  0.867953  1.000000  0.909799   \n",
      "qtzalb_train_60s_3000-2999 -0.042390  0.484819  0.851979  0.975129  0.879023   \n",
      "\n",
      "                                 155       156       157       158       159  \\\n",
      "foalb_train_15s_5250-0      0.575121  0.374501  0.214882  0.110848  0.052384   \n",
      "foalb_train_15s_5250-1      0.610553  0.400672  0.231894  0.118449  0.050007   \n",
      "foalb_train_15s_5250-2      0.610030  0.396653  0.224569  0.110042  0.043800   \n",
      "foalb_train_15s_5250-3      0.644262  0.417962  0.233161  0.109190  0.038269   \n",
      "foalb_train_15s_5250-4      0.613535  0.402683  0.231916  0.117012  0.049544   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  0.687470  0.450134  0.261362  0.140541  0.075679   \n",
      "qtzalb_train_60s_3000-2996  0.676007  0.442381  0.254903  0.133389  0.066652   \n",
      "qtzalb_train_60s_3000-2997  0.662341  0.419229  0.227013  0.108424  0.052630   \n",
      "qtzalb_train_60s_3000-2998  0.693727  0.457279  0.268487  0.147722  0.083483   \n",
      "qtzalb_train_60s_3000-2999  0.661224  0.428035  0.247301  0.137564  0.084017   \n",
      "\n",
      "                            ...      1091      1092      1093      1094  \\\n",
      "foalb_train_15s_5250-0      ...  0.043605  0.108542  0.231170  0.423100   \n",
      "foalb_train_15s_5250-1      ...  0.060088  0.132701  0.256954  0.444917   \n",
      "foalb_train_15s_5250-2      ...  0.050517  0.116672  0.240004  0.431777   \n",
      "foalb_train_15s_5250-3      ...  0.048278  0.117221  0.243527  0.437172   \n",
      "foalb_train_15s_5250-4      ...  0.026982  0.096095  0.226407  0.426401   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  ...  0.052431  0.120275  0.244638  0.435690   \n",
      "qtzalb_train_60s_3000-2996  ...  0.053233  0.121710  0.246460  0.438206   \n",
      "qtzalb_train_60s_3000-2997  ...  0.028918  0.101945  0.234712  0.434680   \n",
      "qtzalb_train_60s_3000-2998  ...  0.057637  0.117994  0.235801  0.423637   \n",
      "qtzalb_train_60s_3000-2999  ...  0.050512  0.123393  0.252465  0.446472   \n",
      "\n",
      "                                1095      1096      1097      1098      1099  \\\n",
      "foalb_train_15s_5250-0      0.665607  0.892756  1.000000  0.889557  0.534266   \n",
      "foalb_train_15s_5250-1      0.679952  0.899042  1.000000  0.885818  0.528646   \n",
      "foalb_train_15s_5250-2      0.672732  0.896805  1.000000  0.885514  0.527092   \n",
      "foalb_train_15s_5250-3      0.677976  0.899930  1.000000  0.882585  0.522179   \n",
      "foalb_train_15s_5250-4      0.673323  0.898984  1.000000  0.882515  0.523523   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "qtzalb_train_60s_3000-2995  0.673449  0.892330  0.990129  0.872321  0.514130   \n",
      "qtzalb_train_60s_3000-2996  0.677611  0.899222  1.000000  0.883834  0.524544   \n",
      "qtzalb_train_60s_3000-2997  0.679372  0.901830  1.000000  0.880722  0.520925   \n",
      "qtzalb_train_60s_3000-2998  0.662419  0.885848  0.989848  0.877629  0.522615   \n",
      "qtzalb_train_60s_3000-2999  0.685111  0.903437  1.000000  0.880402  0.519435   \n",
      "\n",
      "                            label  \n",
      "foalb_train_15s_5250-0         14  \n",
      "foalb_train_15s_5250-1         14  \n",
      "foalb_train_15s_5250-2         14  \n",
      "foalb_train_15s_5250-3         14  \n",
      "foalb_train_15s_5250-4         14  \n",
      "...                           ...  \n",
      "qtzalb_train_60s_3000-2995     12  \n",
      "qtzalb_train_60s_3000-2996     12  \n",
      "qtzalb_train_60s_3000-2997     12  \n",
      "qtzalb_train_60s_3000-2998     12  \n",
      "qtzalb_train_60s_3000-2999     12  \n",
      "\n",
      "[23271 rows x 951 columns]\n"
     ]
    }
   ],
   "source": [
    "'''train the model'''\n",
    "test_outputs_df,model,pca=tmodel.classic_model(training_set_path,test_set_path,output_label,False,1,r'SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEAAkuTBHgH3"
   },
   "source": [
    "<h1>Training the Binary Classifier Ensemble</h1>\n",
    "\n",
    "<p>If you need to retrain the models, be sure to restart the runtime</p>\n",
    "\n",
    "<h3>Train below</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1593641791363,
     "user": {
      "displayName": "Nathan Temiquel",
      "photoUrl": "",
      "userId": "01657354188638757810"
     },
     "user_tz": 420
    },
    "id": "NmrT68QWPumc"
   },
   "outputs": [],
   "source": [
    "'''define the filepaths for your data here!'''\n",
    "\n",
    "output_label='testing_1_1-11(4)'\n",
    "training_set_path='Data/CWT Data/Single/'\n",
    "test_set_path='Data/CWT Data/Mixed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104408,
     "status": "ok",
     "timestamp": 1593641897400,
     "user": {
      "displayName": "Nathan Temiquel",
      "photoUrl": "",
      "userId": "01657354188638757810"
     },
     "user_tz": 420
    },
    "id": "n1cWmQtCGmrF",
    "outputId": "15bd0462-31e2-4cd3-bff4-ea127369b506",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''train the model'''\n",
    "test_outputs_df,model_ls,pca_ls=tmodel.binary_model_set(training_set_path,test_set_path,output_label,False,1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "stable_7-1-20_CNN_using_CWT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
