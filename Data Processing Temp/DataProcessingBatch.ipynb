{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataProcessingBatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc108ESHE4in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0838929-1cce-4f96-bed5-88c888a06189"
      },
      "source": [
        "'''Same as DataProcessing_long, use for batches of files'''\n",
        "#import pd, np, signal for data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTYoML56FPjN"
      },
      "source": [
        "def remove_repeat(file_ls,svd_fil):\n",
        "  #try to read in the saved data\n",
        "  try:\n",
        "    saved_s=pd.read_csv(svd_fil,index_col=0,header=None,squeeze=True)\n",
        "  except FileNotFoundError:\n",
        "    print('History file not found, all data files being processed')\n",
        "    return file_ls,False\n",
        "  \n",
        "  #somewhat clunky (but effective) method for checking if we've processed a file already\n",
        "  temp_s=pd.Series(file_ls)\n",
        "  tf_ls=temp_s.isin(saved_s)\n",
        "  idx_ls=[]\n",
        "  for i in range(0,len(tf_ls)):\n",
        "    if tf_ls[i]:\n",
        "      idx_ls.append(i)\n",
        "  temp_s.drop(index=idx_ls,inplace=True)\n",
        "  return temp_s.tolist(),True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asolyz2Qqwis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "b0788fa2-940b-4100-e4ee-a6ea932728e8"
      },
      "source": [
        "#set filepaths for import/export\n",
        "\n",
        "#ONLY PROCESS ONE FILE PATH WHEN RUNNING THE PROGRAM - comment the other\n",
        "#file in path for synthetic data\n",
        "#fin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Synthetic Data/Basic Synthetic Data/'\n",
        "#file in path for raw data\n",
        "fin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Raw Data/'\n",
        "\n",
        "cwtout_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Continuous Wavelet Transformation/'\n",
        "pkout_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Peaks Only/'\n",
        "saved_data=r'/content/drive/My Drive/ML Spectroscopy/Programs/Data Processing/Saved Lists/processed_files.csv'\n",
        "\n",
        "'''list of base filenames, note marbledslab, and granitegrid[...] \n",
        "require clustering for labels (hence 'None'). blackmin[...] excluded due to a \n",
        "lack of known label'''\n",
        "\n",
        "#Find all files in data directory\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "fname_ls = [f for f in listdir(fin_path) if isfile(join(fin_path,f))]\n",
        "\n",
        "fname_ls,fflag=remove_repeat(file_ls=fname_ls,svd_fil=saved_data)\n",
        "\n",
        "if not fname_ls:\n",
        "  raise ValueError('No new files')\n",
        "#define the training labels in a dict - labels taken from \"0-Uploaded Data\" sheet \n",
        "t_labels={\n",
        "    'qtz':0,\n",
        "    'albite':1,\n",
        "    'hb':2,\n",
        "    'bt':3,\n",
        "    'ms':4,\n",
        "    'fo':5,\n",
        "    'aug':6,\n",
        "    'en':7,\n",
        "    'an':8,\n",
        "    'mc':9,\n",
        "    'cal':10,\n",
        "    'gyp':11,\n",
        "    'qtzalb':12,\n",
        "    'foaug':13,\n",
        "    'foalb':14\n",
        "}\n",
        "\n",
        "fname_d={}\n",
        "\n",
        "for fil in fname_ls:\n",
        "  try:\n",
        "    fname_d[fil]=t_labels[fil.split('_')[0]]\n",
        "  except:\n",
        "    fname_d[fil]=None\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d6983eb081d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname_ls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No new files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#define the training labels in a dict - labels taken from \"0-Uploaded Data\" sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m t_labels={\n",
            "\u001b[0;31mValueError\u001b[0m: No new files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLIk8_zDcPy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26930296-0788-476f-c8a3-903b96f2e918"
      },
      "source": [
        "print(fname_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'qtz_train_003s_4760_ds2.csv': 0, 'qtz_train_003s_4760_ds4.csv': 0, 'qtz_train_003s_4760_r.csv': 0, 'qtz_train_003s_4760_r_ds2.csv': 0, 'qtz_train_003s_4760_r_ds4.csv': 0, 'qtz_train_003s_1148_ds2.csv': 0, 'qtz_train_003s_1148_ds4.csv': 0, 'qtz_train_003s_1148_r.csv': 0, 'qtz_train_003s_1148_r_ds4.csv': 0, 'qtz_train_003s_1148_r_ds2.csv': 0, 'qtz_train_003s-1599_ds2.csv': 0, 'qtz_train_003s-1599_ds4.csv': 0, 'qtz_train_003s-1599_r.csv': 0, 'qtz_train_003s-1599_r_ds2.csv': 0, 'qtz_train_003s-1599_r_ds4.csv': 0, 'qtz_train_005s_0900_ds2.csv': 0, 'qtz_train_005s_0900_ds4.csv': 0, 'qtz_train_005s_0900_r.csv': 0, 'qtz_train_005s_0900_r_ds2.csv': 0, 'qtz_train_005s_0900_r_ds4.csv': 0, 'albite_train_015s_5250_ds4.csv': 1, 'albite_train_015s_5250_ds2.csv': 1, 'albite_train_015s_5250_r.csv': 1, 'albite_train_015s_5250_r_ds2.csv': 1, 'albite_train_015s_5250_r_ds4.csv': 1, 'qtz_train_005s_1000_ds2.csv': 0, 'qtz_train_005s_1000_ds4.csv': 0, 'qtz_train_005s_1000_r.csv': 0, 'qtz_train_005s_1000_r_ds2.csv': 0, 'qtz_train_005s_1000_r_ds4.csv': 0, 'hb_train_120s_1225_01_ds2.csv': 2, 'hb_train_120s_1225_01_ds4.csv': 2, 'hb_train_120s_1225_01_r.csv': 2, 'hb_train_120s_1225_01_r_ds2.csv': 2, 'hb_train_120s_1225_01_r_ds4.csv': 2, 'hb_train_120s_1225_02_ds2.csv': 2, 'hb_train_120s_1225_02_ds4.csv': 2, 'hb_train_120s_1225_02_r.csv': 2, 'hb_train_120s_1225_02_r_ds4.csv': 2, 'hb_train_120s_1225_02_r_ds2.csv': 2, 'bt_train_120s_1225_ds2.csv': 3, 'bt_train_120s_1225_ds4.csv': 3, 'bt_train_120s_1225_r.csv': 3, 'bt_train_120s_1225_r_ds4.csv': 3, 'bt_train_120s_1225_r_ds2.csv': 3, 'albite_train_015s_625_ds2.csv': 1, 'albite_train_015s_625_ds4.csv': 1, 'albite_train_015s_625_r_ds2.csv': 1, 'albite_train_015s_625_r.csv': 1, 'albite_train_015s_625_r_ds4.csv': 1, 'qtz_train_015s_625_ds2.csv': 0, 'qtz_train_015s_625_ds4.csv': 0, 'qtz_train_015s_625_r.csv': 0, 'qtz_train_015s_625_r_ds2.csv': 0, 'qtz_train_015s_625_r_ds4.csv': 0, 'granite0dust_test_015s_5184_ds2.csv': None, 'granite0dust_test_015s_5184_ds4.csv': None, 'granite0dust_test_015s_5184_r.csv': None, 'granite0dust_test_015s_5184_r_ds2.csv': None, 'granite0dust_test_015s_5184_r_ds4.csv': None, 'fo_train_030s_5040_ds2.csv': 5, 'fo_train_030s_5040_ds4.csv': 5, 'fo_train_030s_5040_r.csv': 5, 'fo_train_030s_5040_r_ds2.csv': 5, 'fo_train_030s_5040_r_ds4.csv': 5, 'granite0dust_test_015s_6400_ds2.csv': None, 'granite0dust_test_015s_6400_ds4.csv': None, 'granite0dust_test_015s_6400_r.csv': None, 'granite0dust_test_015s_6400_r_ds2.csv': None, 'granite0dust_test_015s_6400_r_ds4.csv': None, 'hb_train_060s_104_ds2.csv': 2, 'hb_train_060s_104_ds4.csv': 2, 'hb_train_060s_104_r_ds2.csv': 2, 'hb_train_060s_104_r.csv': 2, 'hb_train_060s_104_r_ds4.csv': 2, 'hb_train_015s_2500_ds2.csv': 2, 'hb_train_015s_2500_ds4.csv': 2, 'hb_train_015s_2500_r.csv': 2, 'hb_train_015s_2500_r_ds2.csv': 2, 'hb_train_015s_2500_r_ds4.csv': 2, 'granite50dust_test_015s_10000_ds2.csv': None, 'granite50dust_test_015s_10000_ds4.csv': None, 'granite50dust_test_015s_10000_r.csv': None, 'granite50dust_test_015s_10000_r_ds2.csv': None, 'granite50dust_test_015s_10000_r_ds4.csv': None, 'aug_train_030s_5600_ds2.csv': 6, 'aug_train_030s_5600_ds4.csv': 6, 'aug_train_030s_5600_r.csv': 6, 'aug_train_030s_5600_r_ds2.csv': 6, 'aug_train_030s_5600_r_ds4.csv': 6, 'en_train_015s_5600_ds2.csv': 7, 'en_train_015s_5600_ds4.csv': 7, 'en_train_015s_5600_r.csv': 7, 'en_train_015s_5600_r_ds2.csv': 7, 'en_train_015s_5600_r_ds4.csv': 7, 'ms_train_015s_6400_ds2.csv': 4, 'ms_train_015s_6400_ds4.csv': 4, 'ms_train_015s_6400_r.csv': 4, 'ms_train_015s_6400_r_ds2.csv': 4, 'ms_train_015s_6400_r_ds4.csv': 4, 'mc_train_015s_5600_ds2.csv': 9, 'mc_train_015s_5600_ds4.csv': 9, 'mc_train_015s_5600_r.csv': 9, 'mc_train_015s_5600_r_ds2.csv': 9, 'mc_train_015s_5600_r_ds4.csv': 9, 'bt_train_015s_5600_ds2.csv': 3, 'bt_train_015s_5600_ds4.csv': 3, 'bt_train_015s_5600_r.csv': 3, 'bt_train_015s_5600_r_ds2.csv': 3, 'bt_train_015s_5600_r_ds4.csv': 3, 'gabbro0dust_test_015s_1020_ds2.csv': None, 'gabbro0dust_test_015s_1020_ds4.csv': None, 'gabbro0dust_test_015s_1020_r.csv': None, 'gabbro0dust_test_015s_1020_r_ds2.csv': None, 'gabbro0dust_test_015s_1020_r_ds4.csv': None, 'an_train_015s_5600_ds2.csv': 8, 'an_train_015s_5600_ds4.csv': 8, 'an_train_015s_5600_r.csv': 8, 'an_train_015s_5600_r_ds2.csv': 8, 'an_train_015s_5600_r_ds4.csv': 8, 'qtzalb_train_60s_3000_ds2.csv': 12, 'qtzalb_train_60s_3000_ds4.csv': 12, 'qtzalb_train_60s_3000_r.csv': 12, 'qtzalb_train_60s_3000_r_ds2.csv': 12, 'qtzalb_train_60s_3000_r_ds4.csv': 12, 'qtzalb_train_30s_2000_ds2.csv': 12, 'qtzalb_train_30s_2000_ds4.csv': 12, 'qtzalb_train_30s_2000_r.csv': 12, 'qtzalb_train_30s_2000_r_ds2.csv': 12, 'qtzalb_train_30s_2000_r_ds4.csv': 12, 'cal_train_1s_2732_ds2.csv': 10, 'cal_train_1s_2732_ds4.csv': 10, 'cal_train_1s_2732_r.csv': 10, 'cal_train_1s_2732_r_ds2.csv': 10, 'cal_train_1s_2732_r_ds4.csv': 10, 'cal_train_1s_2300_ds2.csv': 10, 'cal_train_1s_2300_ds4.csv': 10, 'cal_train_1s_2300_r.csv': 10, 'cal_train_1s_2300_r_ds2.csv': 10, 'cal_train_1s_2300_r_ds4.csv': 10, 'gyp_train_15s_1680_ds2.csv': 11, 'gyp_train_15s_1680_ds4.csv': 11, 'gyp_train_15s_1680_r.csv': 11, 'gyp_train_15s_1680_r_ds2.csv': 11, 'gyp_train_15s_1680_r_ds4.csv': 11, 'foalb_train_15s_5250_ds2.csv': 14, 'foalb_train_15s_5250_ds4.csv': 14, 'foalb_train_15s_5250_r.csv': 14, 'foalb_train_15s_5250_r_ds2.csv': 14, 'foalb_train_15s_5250_r_ds4.csv': 14, 'foaug_train_60s_5040_ds2.csv': 13, 'foaug_train_60s_5040_ds4.csv': 13, 'foaug_train_60s_5040_r.csv': 13, 'foaug_train_60s_5040_r_ds2.csv': 13, 'foaug_train_60s_5040_r_ds4.csv': 13, 'gyp_train_12s_3336_ds2.csv': 11, 'gyp_train_12s_3336_ds4.csv': 11, 'gyp_train_12s_3336_r.csv': 11, 'gyp_train_12s_3336_r_ds2.csv': 11, 'gyp_train_12s_3336_r_ds4.csv': 11, 'granite0dust_test_015s_4839_ds2.csv': None, 'granite0dust_test_015s_4839_ds4.csv': None, 'granite0dust_test_015s_4839_r.csv': None, 'granite0dust_test_015s_4839_r_ds2.csv': None, 'granite0dust_test_015s_4839_r_ds4.csv': None, 'granite0dust_test_015s_1061_ds2.csv': None, 'granite0dust_test_015s_1061_ds4.csv': None, 'granite0dust_test_015s_1061_r.csv': None, 'granite0dust_test_015s_1061_r_ds2.csv': None, 'granite0dust_test_015s_1061_r_ds4.csv': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYyKmcoQsLWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b914c0-fe36-448c-e83f-fceeca6bc1a3"
      },
      "source": [
        "for key,val in fname_d.items():\n",
        "  if key.split('.')[-1]=='txt':\n",
        "    df=pd.read_csv(fin_path+key,delim_whitespace=True)\n",
        "    if df.shape[1]<20:\n",
        "      df=pd.read_csv(fin_path+key,sep='\\t')\n",
        "  else:\n",
        "    df=pd.read_csv(fin_path+key,delim_whitespace=False)\n",
        "  df.reset_index(inplace=True)\n",
        "\n",
        "  #create traceable index\n",
        "  df['fname']=key.split('.')[0]\n",
        "  df['og-idx']=df.fname+\"-\"+df.index.map(str)\n",
        "  df.set_index(keys='og-idx',drop=True,inplace=True)\n",
        "  \n",
        "  #drop non-numeric columns from data\n",
        "  dropcolumns=[]\n",
        "  for i in df.columns.values:\n",
        "    try:\n",
        "      float(i)\n",
        "    except ValueError:\n",
        "      dropcolumns.append(i)\n",
        "\n",
        "  df.drop(columns=dropcolumns,inplace=True)\n",
        "\n",
        "  #trim to cols to [150,1100]\n",
        "  df.drop(columns=[i for i in df.columns.values if float(i)<150.],inplace=True)\n",
        "  df.drop(columns=[i for i in df.columns.values if float(i)>1100.],inplace=True)\n",
        "  \n",
        "  #standardize wavelength\n",
        "  new_wavelength=1\n",
        "  starting_wave=150\n",
        "  ending_wave=1100\n",
        "  std_df=pd.DataFrame()\n",
        "\n",
        "  for i in range(starting_wave,ending_wave,new_wavelength):\n",
        "    std_df[i]=df[[j for j in df.columns.values if i<=float(j)<(i+new_wavelength)]].min(axis=1)\n",
        "\n",
        "  #implement cwt\n",
        "  c_vals=std_df.columns.values.tolist()\n",
        "  wvlt=signal.ricker\n",
        "  smth_df=pd.DataFrame(columns=c_vals)\n",
        "\n",
        "  for idx, row in std_df.iterrows():\n",
        "    smth_df=smth_df.append(other=pd.Series(signal.cwt(data=row,widths=[3],wavelet=wvlt)[0,:],name=idx,index=c_vals))\n",
        "\n",
        "  #scale df to [-1,1]\n",
        "  scl_df=smth_df.divide(smth_df.max(1),axis=0)\n",
        "\n",
        "  #find peaks\n",
        "  pk_ls=[['peak1','peak2','peak3','peak4','peak5','val1','val2','val3','val4','val5']]\n",
        "  for idx,row in std_df.iterrows():\n",
        "    #print(idx,'\\n',row,'\\n\\n')\n",
        "    if row.sum()<100:\n",
        "      continue\n",
        "    pk_wv_ls=std_df.columns.values[signal.find_peaks_cwt(row,widths=[3],wavelet=wvlt)][1:-1] \n",
        "    temp_vals=pd.Series(scl_df.iloc[std_df.index.get_loc(std_df.loc[idx].name)][pk_wv_ls],index=pk_wv_ls)\n",
        "    temp_s=temp_vals.nlargest(n=5)\n",
        "    pk_wv=temp_s.index.values.tolist()\n",
        "    pk_vl=temp_s.tolist()\n",
        "    pk_ls.append(pk_wv + pk_vl)\n",
        "  try:\n",
        "    pk_df=pd.DataFrame(pk_ls[1:],index=std_df.index.values,columns=pk_ls[0])\n",
        "    pk_flag=True\n",
        "  except:\n",
        "    pk_flag=False\n",
        "  print()\n",
        "\n",
        "  #check if data has a label, add if it exists\n",
        "\n",
        "  if val is None:\n",
        "    final_cwt_path=cwtout_path+r'Unlabeled/cwt_'+key\n",
        "    final_pk_path=pkout_path+r'Unlabeled/pk_'+key\n",
        "  else:\n",
        "    scl_df['label']=val\n",
        "    if pk_flag:\n",
        "      pk_df['label']=val\n",
        "    final_cwt_path=cwtout_path+r'Labeled/L_cwt_'+key\n",
        "    final_pk_path=pkout_path+r'Labeled/L_pk_'+key\n",
        "\n",
        "\n",
        "  #output files\n",
        "  scl_df.to_csv(final_cwt_path)\n",
        "  if pk_flag:\n",
        "    pk_df.to_csv(final_pk_path)\n",
        "\n",
        "  print(key,'labeled')\n",
        "\n",
        "\n",
        "\n",
        "  if fflag:\n",
        "    pd.Series(key).to_csv(saved_data,mode='a')\n",
        "  else:\n",
        "    pd.Series(key).to_csv(saved_data,mode='w')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/signal/_peak_finding.py:77: RuntimeWarning: invalid value encountered in greater\n",
            "  results &= comparator(main, plus)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/signal/_peak_finding.py:78: RuntimeWarning: invalid value encountered in greater\n",
            "  results &= comparator(main, minus)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-287605b29bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mpk_wv_ls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_peaks_cwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwavelet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwvlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mtemp_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpk_wv_ls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpk_wv_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtemp_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdni1gaVbIFr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}