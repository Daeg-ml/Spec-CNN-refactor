{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression_synth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjoK0CooyLaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b11b0608-8521-4d32-8a73-4c930d884fc6"
      },
      "source": [
        "'''clear to run, check with nate if issues'''\n",
        "\n",
        "\n",
        "#import pandas for data processing\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6znpiKhys4I"
      },
      "source": [
        "def fname_ls_builder(fin_path,initial=True):\n",
        "  #Find all files in data directory\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  if initial:\n",
        "    return [f for f in listdir(fin_path) if isfile(join(fin_path,f)) and (not ('_ds' in f or '_r' in f))]\n",
        "  else:\n",
        "    return [f for f in listdir(fin_path) if (isfile(join(fin_path,f)) and ('_ds' in f or '_r' in f))]\n",
        "\n",
        "def df_builder(fin_path,fname_ls):\n",
        "  #this function imports data from CSV files to one large dataframe\n",
        "\n",
        "  #create list to hold dataframes\n",
        "  df_ls=[]\n",
        "\n",
        "  #read in each file\n",
        "  for i in fname_ls:\n",
        "    temp_df=pd.read_csv(fin_path+i,index_col=0)\n",
        "    #print(i,'loaded\\n\\n')\n",
        "    df_ls.append(temp_df)\n",
        "\n",
        "  #create one large df\n",
        "  df=pd.concat(df_ls)\n",
        "  #print(df.shape)\n",
        "  return df\n",
        "\n",
        "def split_data(X):\n",
        "  #separate y from X\n",
        "  y=X['label']\n",
        "  X.drop(['label'],axis=1,inplace=True)\n",
        "  #split into train and dev sets\n",
        "  #print(X,'\\n\\n',y)\n",
        "  return X,y\n",
        "\n",
        "\n",
        "#set filepaths for import/export\n",
        "pkin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Peaks Only/Labeled/'\n",
        "\n",
        "pk_fname_ls=fname_ls_builder(pkin_path)\n",
        "\n",
        "pk_df=df_builder(pkin_path,pk_fname_ls)\n",
        "\n",
        "#drop relative intensities\n",
        "pk_df.drop(columns=[i for i in pk_df.columns.values if 'val' in i],inplace=True)\n",
        "\n",
        "pk_df,y=split_data(pk_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88D5b67EBntx"
      },
      "source": [
        "#split into train and dev sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(pk_df, y, test_size = 0.20, random_state = 0)\n",
        "#print(X_train,'\\n\\n',X_dev,'\\n\\n',y_train,'\\n\\n',y_dev)\n",
        "\n",
        "#build a df of synthetic data for the training set\n",
        "pk_fname_ls2=fname_ls_builder(pkin_path,initial=False)\n",
        "pk_df2=df_builder(pkin_path,pk_fname_ls2)\n",
        "\n",
        "#create columns to compare similar samples\n",
        "temp_pk=pk_df2.copy()\n",
        "X_temp=X_train.copy()\n",
        "temp_pk.index.name='temp'\n",
        "X_temp.index.name='temp'\n",
        "#print('test X_train', X_train,'\\n\\n\\n\\n')\n",
        "temp_pk.reset_index(inplace=True)\n",
        "X_temp.reset_index(inplace=True)\n",
        "temp_pk.rename(columns={temp_pk.index.name:'temp'},inplace=True)\n",
        "#print(X_temp,'\\n\\n',temp_pk,'\\n\\nX_train\\n\\n',X_train)\n",
        "\n",
        "#print(X_temp['temp'].str.split('-',expand=True)[[0,1]])\n",
        "X_temp[['file','line']]=X_temp['temp'].str.split('-',expand=True)[[0,1]]\n",
        "temp_pk[['file','line']]=temp_pk['temp'].str.split('-',expand=True)[[0,1]]\n",
        "for i in X_temp.index.values:\n",
        "#for i in range(10):\n",
        "  #print(X_temp.loc[i,['temp']])\n",
        "  temp_df=temp_pk.loc[temp_pk['line']==X_temp.loc[i,['line']].values[0]]\n",
        "  #print('temp should be equal to string above\\n',temp_df)\n",
        "  temp_df=temp_df.loc[temp_df['file'].str.contains(X_temp.loc[i,['file']].values[0])]\n",
        "  \n",
        "  temp_df.set_index(keys=temp_df['temp'],drop=True,inplace=True)\n",
        "  temp_df,temp_y=split_data(temp_df.set_index(keys=temp_df.temp,drop=True).drop(columns=['file','line','temp']))\n",
        "  X_train.append(temp_df)\n",
        "  #print(X_train)\n",
        "  y_train.append(temp_y)\n",
        "  if i%1000==0:\n",
        "    print(i)\n",
        "\n",
        "print(X_train,'\\n\\n',y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GmzJl-v63Jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0384dc4-3f0c-404a-d313-4f20b392af09"
      },
      "source": [
        "#scale data((X-mean)/std_dev)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_sc = sc.fit_transform(X_train)\n",
        "X_dev_sc = sc.fit_transform(X_dev)\n",
        "#print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(225162, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uamWMnnsWEgl"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "#run PCA\n",
        "X_train_p=PCA(n_components=3).fit_transform(X_train_sc)\n",
        "X_dev_p=PCA(n_components=3).fit_transform(X_dev_sc)\n",
        "#print(X_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puy0uSDafO0s"
      },
      "source": [
        "#create model\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "model=LogisticRegression().fit(X_train_sc,y_train)\n",
        "modelp=LogisticRegression().fit(X_train_p,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIsiKSe5wGc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3bec0e5f-7693-4752-8721-49105d046e2c"
      },
      "source": [
        "#check model\n",
        "print(model.score(X_dev_sc,y_dev))\n",
        "print(modelp.score(X_dev_p,Py_dev))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8185552816823218\n",
            "0.7579330713032665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVFT7gaqw2X8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "30004660-88ec-4151-d329-852bb39b90b6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y,model.predict(X_dev_sc))\n",
        "pcm=confusion_matrix(y,modelp.predict(X_dev_p))\n",
        "print(cm,'\\n\\n\\n',pcm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[53500  3331    53  1921  1387     0]\n",
            " [ 4328 30571     5   158   188     0]\n",
            " [  204   217 16213  1115   459 12116]\n",
            " [  126   178  2104 30085  1992  1071]\n",
            " [ 2408  1526    32  1088 25186     0]\n",
            " [    2    50  4255   298   106 28889]] \n",
            "\n",
            "\n",
            " [[52208  3149   433  1103  1121  2178]\n",
            " [ 4274 21588   100   127   181  8980]\n",
            " [  487   980 13545  2131   403 12778]\n",
            " [    4   658  1189 29188  2135  2382]\n",
            " [  623  2887  1075   279 25365    11]\n",
            " [ 1936   316  1945   396    79 28928]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5daVJNOTWTw"
      },
      "source": [
        "testin_path=r'/content/drive/My Drive/ML Spectroscopy/Data/Preprocessed/Peaks Only/Unlabeled/'\n",
        "test_ls=fname_ls_builder(testin_path)\n",
        "test_df=df_builder(testin_path,test_ls)\n",
        "test_df.drop(columns=[i for i in test_df.columns.values if 'val' in i],inplace=True)\n",
        "X_test=sc.fit_transform(test_df)\n",
        "X_test_p=PCA(n_components=3).fit_transform(X_test)\n",
        "\n",
        "saved_data=r'/content/drive/My Drive/ML Spectroscopy/Programs/Data Processing/Saved Lists/'\n",
        "\n",
        "pd.DataFrame(data=model.predict_proba(X_test),index=test_df.index.values,columns=sorted(y.unique())).to_csv(saved_data+r'log_reg.csv')\n",
        "pd.DataFrame(data=modelp.predict_proba(X_test_p),index=test_df.index.values,columns=sorted(y.unique())).to_csv(saved_data+r'log_reg_pca.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}